{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24647cf3",
   "metadata": {},
   "source": [
    "# Plant Disease Classification using ResNet50\n",
    "\n",
    "This notebook implements a plant disease classification model using the ResNet50 architecture. The model is trained on a dataset of plant disease images to classify different types of plant diseases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1333c7",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, let's install the required packages and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a73a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65742d5a",
   "metadata": {},
   "source": [
    "## 2. Data Preparation and Loading\n",
    "\n",
    "Set up the basic configuration parameters and prepare the data directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf646ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMAGE_DIR = 'images/images'\n",
    "IMG_SIZE = (224, 224)  # ResNet50 preferred size\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Get class information\n",
    "classes = sorted([d for d in os.listdir(IMAGE_DIR) if os.path.isdir(os.path.join(IMAGE_DIR, d))])\n",
    "print(\"Number of classes found:\", len(classes))\n",
    "print(\"\\nClasses:\")\n",
    "for idx, cls in enumerate(classes):\n",
    "    print(f\"{idx}: {cls}\")\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35178778",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation Setup\n",
    "\n",
    "Configure data augmentation to improve model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Configure validation data preprocessing\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Create data generators\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    IMAGE_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    IMAGE_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803cf8eb",
   "metadata": {},
   "source": [
    "## 4. Model Architecture with ResNet50\n",
    "\n",
    "Build the model using ResNet50 as the base model and add custom layers for our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba567b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 base model\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(*IMG_SIZE, 3)\n",
    ")\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create model architecture\n",
    "inputs = tf.keras.Input(shape=(*IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1825500",
   "metadata": {},
   "source": [
    "## 5. Training Configuration\n",
    "\n",
    "Set up the training parameters including optimizer, loss function, and callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = SGD(learning_rate=LEARNING_RATE, momentum=0.9)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')]\n",
    ")\n",
    "\n",
    "# Configure callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4005f9",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Train the model using our prepared data generators and monitor the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e105d14c",
   "metadata": {},
   "source": [
    "## 7. Save Model and Final Metrics\n",
    "\n",
    "Save the trained model and display the final training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df240b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('plant_disease_classification_resnet.h5')\n",
    "print('Model saved as plant_disease_classification_resnet.h5')\n",
    "\n",
    "# Display final metrics\n",
    "final_train_accuracy = history.history['accuracy'][-1]\n",
    "final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "print(f\"\\nFinal Training Metrics:\")\n",
    "print(f\"Training Accuracy: {final_train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {final_val_accuracy:.4f}\")\n",
    "print(f\"Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Validation Loss: {final_val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
